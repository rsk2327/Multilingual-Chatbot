{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "cf29666d-aca6-4164-8e5c-c345683765bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "import functools\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04107504-7dae-474b-9527-7427edb6dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41021af1-837c-40af-8904-411f81b69cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2ebb2794-a29b-4afa-8929-35fe3dc5fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"machine_learning_basics.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "store = FAISS.from_documents(docs, OpenAIEmbeddings(), distance_strategy=DistanceStrategy.COSINE)\n",
    "\n",
    "retriever = store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32920c2f-5c07-4228-8ba4-1113311a3d64",
   "metadata": {},
   "source": [
    "### Defining Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0980863f-8164-45bf-b048-6c20f340b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatMessage(object):\n",
    "\n",
    "    def __init__(self, message : BaseMessage, sender : str = None):\n",
    "\n",
    "        self.message = message\n",
    "        self.sender = sender\n",
    "\n",
    "        self.content = message.content\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \n",
    "        return f\"{self.sender} | {self.content}\"\n",
    "\n",
    "def reducer(a : list, b : list | str ) -> list:\n",
    "\n",
    "    if type(b) == list: \n",
    "        return a + b\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "    \n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[ChatMessage], reducer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "acb3db71-23d8-4d38-b8cf-973185530b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_SYSTEM_PROMPT = \"\"\"You are a translator. Translate the text provided by the user into {user_language}. Output only the \n",
    "    translated text. If the text is already in {user_language}, return the user's text as it is.\n",
    "\"\"\"\n",
    "\n",
    "AYA_AGENT_PROMPT = \"\"\"Your name is Aya and you are an assistant that answers questions. Only respond if the question is addressed to you (Aya)!! \n",
    "If its not specifically addressed to you, respond with 'NULL'.\n",
    "    \n",
    "\n",
    "    Obey the following rules while responding : \n",
    "    1. Only use the text provided in the context to answer the question.\n",
    "    2. If you don't know the answer, just say that you don't know. \n",
    "    3. Use three sentences maximum and keep the answer concise.\n",
    "    \n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "SUPERVISOR_AGENT_PROMPT = \"\"\"\n",
    "You are a supervisor tasked with managing the chat messages with Aya, an AI assistant. Given a chat\n",
    "message, identify whether the message was directed to Aya. If so, respond with 'Aya'. Otherwise, \n",
    "respond with 'User'\n",
    "\n",
    "Chat Message : {message}\n",
    "\"\"\"\n",
    "\n",
    "# AYA_AGENT_PROMPT = \"\"\"\n",
    "# You are an assistant and your name is Aya. Only answer questions that are addressed to you (Aya). If they are not addressed to you, just respond with \"Null\". Based on the above instructions answer the following question : \n",
    "\n",
    "# Question : {question}\n",
    "# Context : {context}\n",
    "# Answer : \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "class UserAgent(object):\n",
    "\n",
    "    def __init__(self, llm, user_language):\n",
    "        self.llm = llm\n",
    "        self.user_language = user_language\n",
    "        self.chat_history = []\n",
    "\n",
    "        system_prompt = USER_SYSTEM_PROMPT.format(user_language = user_language)\n",
    "    \n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\", system_prompt,\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name = 'user_text'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.chain = prompt | llm\n",
    "\n",
    "\n",
    "    def set_graph(self, graph):\n",
    "        self.graph = graph\n",
    "\n",
    "    def send_text(self,text):\n",
    "\n",
    "        message = ChatMessage(message = HumanMessage(content=text), sender = self.user_language)\n",
    "\n",
    "        inputs = {\"messages\": [message]}\n",
    "        output = self.graph.invoke(inputs)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def display_chat_history(self):\n",
    "\n",
    "        for i in self.chat_history:\n",
    "            print(i)\n",
    "\n",
    "    \n",
    "    def invoke(self, user_text:str):\n",
    "\n",
    "        output = self.chain.invoke({'user_text':[user_text]})\n",
    "\n",
    "        return output\n",
    "            \n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n ------------\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "class AyaAgent(object):\n",
    "\n",
    "    def __init__(self, llm, retriever):\n",
    "\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "\n",
    "        qa_prompt = ChatPromptTemplate.from_template(AYA_AGENT_PROMPT)\n",
    "\n",
    "        self.chain = qa_prompt | llm \n",
    "\n",
    "    def invoke(self, question : str) -> AIMessage:\n",
    "\n",
    "        print(\"Within aya agent\")\n",
    "        print(question)\n",
    "\n",
    "        context = format_docs(self.retriever.invoke(question))\n",
    "        rag_output = self.chain.invoke({'question':question, 'context':context})\n",
    "        answer = rag_output\n",
    "\n",
    "        return answer\n",
    "          \n",
    "class SupervisorAgent(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(SUPERVISOR_AGENT_PROMPT)\n",
    "    \n",
    "        self.chain = prompt | llm\n",
    "\n",
    "    def invoke(self, message : str) -> str:\n",
    "\n",
    "        print(\"Within supervisor agent\")\n",
    "        print(message)\n",
    "\n",
    "        output = self.chain.invoke(message)\n",
    "        \n",
    "        return output.content\n",
    "    \n",
    "       \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b3d9df60-fc24-46e3-a1c3-919dd2930405",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_agent = UserAgent(llm, \"French\")\n",
    "spanish_agent = UserAgent(llm, \"Spanish\")\n",
    "english_agent = UserAgent(llm, \"English\")\n",
    "\n",
    "aya_agent = AyaAgent(llm, retriever)\n",
    "\n",
    "supervisor_agent = SupervisorAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "542551a8-8fea-4bc8-8d6e-9c762a9a6246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within supervisor agent\n",
      "Aya, whats the capital of India?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aya'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor_agent.invoke(\"Aya, whats the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "360c6ac9-27fb-457c-972d-7ae57f33f7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within aya agent\n",
      "When was SVM invented?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aya_agent.invoke(\"Aya, When was SVM invented?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb507cc-9991-44dd-9bce-5efc0cf94902",
   "metadata": {},
   "source": [
    "### Defining Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0f0cea0a-da99-4143-aba5-a41dcabd7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aya_node(state, agent, name):\n",
    "\n",
    "    print(\"In Aya node\")\n",
    "\n",
    "    latest_message = state[\"messages\"][-1]\n",
    "    print(latest_message)\n",
    "\n",
    "    supervisor_agent = SupervisorAgent()\n",
    "    \n",
    "    agent_check = supervisor_agent.invoke(latest_message.content)\n",
    "\n",
    "    if agent_check == 'Aya':\n",
    "        print(\"Agent check is Aya\")\n",
    "\n",
    "        result = agent.invoke(latest_message.content)\n",
    "\n",
    "        return {\n",
    "        'messages' : [ChatMessage(result, sender = 'Aya')]\n",
    "    }\n",
    "                              \n",
    "    else:\n",
    "        print(\"Agent check is NULL\")\n",
    "        return {'messages':[]}\n",
    "        \n",
    "\n",
    "def get_user_node(state, agent, name):\n",
    "    print(\"In User node\")\n",
    "    \n",
    "\n",
    "    latest_message = state[\"messages\"][-1]\n",
    "    print(latest_message)\n",
    "\n",
    "    result = agent.invoke(latest_message.message)\n",
    "    \n",
    "    agent.chat_history.append(result.content)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [ChatMessage(result, sender = name)],\n",
    "        \n",
    "    }\n",
    "\n",
    "def get_supervisor_node(state, agent : SupervisorAgent):\n",
    "\n",
    "    print(\"In supervisor node\")\n",
    "    latest_message = state[\"messages\"][-1]\n",
    "    print(latest_message)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # result = agent.invoke(latest_message.content)\n",
    "\n",
    "    # print(result)\n",
    "\n",
    "    return {'messages': []} \n",
    "\n",
    "french_node = functools.partial(get_user_node, agent=french_agent, name=\"French\")\n",
    "spanish_node = functools.partial(get_user_node, agent=spanish_agent, name=\"Spanish\")\n",
    "english_node = functools.partial(get_user_node, agent=english_agent, name=\"English\")\n",
    "\n",
    "aya_node = functools.partial(get_aya_node, agent = aya_agent, name =\"Aya\")\n",
    "\n",
    "supervisor_node = functools.partial(get_supervisor_node, agent = supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3a226a48-e677-4a0a-9bd6-f4645b995c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# agentList = {'French':{'node':french_node, 'agent':french_agent},\n",
    "#                    'Spanish':{'node':spanish_node, 'agent':spanish_agent},\n",
    "#                    'English':{'node':english_node, 'agent':english_agent},\n",
    "#                    }\n",
    "\n",
    "agentList = {\n",
    "                   'English':{'node':english_node, 'agent':english_agent},\n",
    "                   }\n",
    "                  \n",
    "\n",
    "#Defining nodes\n",
    "for agent in agentList:\n",
    "    workflow.add_node(agent, agentList[agent]['node'])\n",
    "\n",
    "workflow.add_node(\"Supervisor\", supervisor_node)\n",
    "\n",
    "#Defining edges\n",
    "workflow.add_edge(START, \"Supervisor\")\n",
    "\n",
    "for agent in agentList:\n",
    "    workflow.add_edge(\"Supervisor\", agent)\n",
    "    workflow.add_edge(agent, END)\n",
    "\n",
    "\n",
    "workflow.add_node(\"Aya\",aya_node) \n",
    "\n",
    "workflow.add_edge(\"Supervisor\",\"Aya\")\n",
    "\n",
    "def router2(state) :\n",
    "    print(\"Within router\")\n",
    "    \n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.sender == \"Aya\":\n",
    "        return \"END\"\n",
    "    else:\n",
    "        return 'Aya'\n",
    "\n",
    "workflow.add_conditional_edges(\"Supervisor\", router2  ,{'Aya':'Aya','END':END})\n",
    "\n",
    "def router(state) :\n",
    "    print(\"Within router\")\n",
    "    \n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.sender == \"Aya\":\n",
    "        print(\"\")\n",
    "        return \"Supervisor\"\n",
    "    else:\n",
    "        return 'END'\n",
    "        \n",
    "workflow.add_conditional_edges(\"Aya\", router, {'Supervisor':'Supervisor','END':END})\n",
    "   \n",
    "# supervisor_router = functools.partial(router, agent = supervisor_agent)\n",
    "\n",
    "# workflow.add_conditional_edges(\"Supervisor\", supervisor_router, {\"Aya\": \"Aya\", \"skip\": END})\n",
    "\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "french_agent.set_graph(app)\n",
    "spanish_agent.set_graph(app)\n",
    "english_agent.set_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9b55694e-6503-49ec-b4ef-e0e43925c457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In supervisor node\n",
      "English | Aya, when was SVM invented?\n",
      "Within router\n",
      "In User node\n",
      "English | Aya, when was SVM invented?\n",
      "In Aya node\n",
      "English | Aya, when was SVM invented?\n",
      "Within supervisor agent\n",
      "Aya, when was SVM invented?\n",
      "Agent check is Aya\n",
      "Within aya agent\n",
      "Aya, when was SVM invented?\n",
      "Within router\n",
      "\n",
      "In supervisor node\n",
      "Aya | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "Within router\n",
      "In User node\n",
      "Aya | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "In Aya node\n",
      "Aya | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "Within supervisor agent\n",
      "Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "Agent check is NULL\n",
      "Within router\n",
      "\n",
      "In supervisor node\n",
      "English | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "Within router\n",
      "In User node\n",
      "English | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "In Aya node\n",
      "English | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "Within supervisor agent\n",
      "Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.\n",
      "Agent check is NULL\n",
      "Within router\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [English | Aya, when was SVM invented?,\n",
       "  English | Aya, when was SVM invented?,\n",
       "  Aya | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.,\n",
       "  English | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.,\n",
       "  English | Support Vector Machines (SVMs) were invented by researchers at AT&T in 1992.]}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_agent.send_text(\"Aya, when was SVM invented?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "264617cc-97fb-443e-b41e-ebe458c4c8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeColors\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "145d02eb-f113-41bd-9042-e17f1841da3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In supervisor node\n",
      "{'messages': [Aya, whats the capital of India?]}\n",
      "Within supervisor agent\n",
      "Aya, whats the capital of India?\n",
      "content='Aya' response_metadata={'finish_reason': 'stop'} id='run-066390f9-3263-4d81-ac71-cd324928c1c6-0'\n",
      "Within supervisor agent\n",
      "Aya, whats the capital of India?\n",
      "In User nodeIn User node\n",
      "{'messages': [Aya, whats the capital of India?]}\n",
      "\n",
      "{'messages': [Aya, whats the capital of India?]}\n",
      "In User node\n",
      "{'messages': [Aya, whats the capital of India?]}\n",
      "In supervisor node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n",
      "content='Aya' response_metadata={'finish_reason': 'stop'} id='run-f755b329-bd1d-4795-bb4b-b87fbe46ffdf-0'\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n",
      "In User nodeIn User node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "In User node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "In supervisor node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n",
      "content='Aya' response_metadata={'finish_reason': 'stop'} id='run-4679f931-8312-4e08-ac06-b20c060b7492-0'\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n",
      "In User nodeIn User node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "In User node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "In supervisor node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n",
      "content='Aya' response_metadata={'finish_reason': 'stop'} id='run-6d963f63-b8c1-4b36-a545-3ec587e6f102-0'\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n",
      "In User nodeIn User node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "In User node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "In supervisor node\n",
      "{'messages': [Aya, whats the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?, Aya, quelle est la capitale de l'Inde?, Aya, ¿cuál es la capital de India?, Aya, what's the capital of India?]}\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n",
      "content='Aya' response_metadata={'finish_reason': 'stop'} id='run-669d49c9-6484-4ab0-bdd5-9a01b2a746a4-0'\n",
      "Within supervisor agent\n",
      "Aya, what's the capital of India?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[267], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menglish_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAya, whats the capital of India?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[242], line 65\u001b[0m, in \u001b[0;36mUserAgent.send_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     62\u001b[0m message \u001b[38;5;241m=\u001b[39m ChatMessage(message \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39mtext), sender \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_language)\n\u001b[1;32m     64\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [message]}\n\u001b[0;32m---> 65\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/base/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1333\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1333\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/base/lib/python3.11/site-packages/langgraph/pregel/__init__.py:869\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    862\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    863\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(run_with_retry, task, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy)\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m next_tasks\n\u001b[1;32m    865\u001b[0m ]\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# execute tasks, and wait for one to fail or all to finish.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# each task is independent from all other concurrent tasks\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_EXCEPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m    876\u001b[0m _panic_or_proceed(done, inflight, step)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b1f2c1fd-4489-416d-8fe4-7cfda5bccec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In supervisor\n",
      "{'messages': [hey there!]}\n",
      "<class 'dict'>\n",
      "Within supervisor agent\n",
      "hey there!\n",
      "In UserIn User\n",
      "{'messages': [hey there!]}\n",
      "hey there!\n",
      "In User\n",
      "{'messages': [hey there!]}\n",
      "hey there!\n",
      "\n",
      "{'messages': [hey there!]}\n",
      "hey there!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [hey there!, salut là-bas!, ¡Hola!, hey there!]}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_agent.send_text(\"hey there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1ad3f7c0-af4c-4c30-baf6-a09d98b4d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In supervisor\n",
      "{'messages': [How are you?]}\n",
      "<class 'dict'>\n",
      "Within supervisor agent\n",
      "How are you?\n",
      "In UserIn User\n",
      "{'messages': [How are you?]}\n",
      "How are you?\n",
      "\n",
      "{'messages': [How are you?]}\n",
      "How are you?\n",
      "In User\n",
      "{'messages': [How are you?]}\n",
      "How are you?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [How are you?, Comment ça va ?, ¿Cómo estás?, How are you?]}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_agent.send_text(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d3c0ea8-3869-4e2b-bb19-feffef27d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in supervisor\n",
      "{'messages': [HumanMessage(content='lo estoy haciendo bien. ¿Y tú?')], 'sender': None}\n",
      "content='lo estoy haciendo bien. ¿Y tú?'\n",
      "content='lo estoy haciendo bien. ¿Y tú?'\n",
      "content='lo estoy haciendo bien. ¿Y tú?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='lo estoy haciendo bien. ¿Y tú?'),\n",
       "  AIMessage(content='Je le fais bien. Et toi?', response_metadata={'finish_reason': 'stop'}, id='run-0404cc91-b7fc-465a-bba7-c635dcb1a817-0'),\n",
       "  AIMessage(content=\"I'm doing well. And you?\", response_metadata={'finish_reason': 'stop'}, id='run-691655aa-49bf-4fd4-b472-8293f85bfb41-0'),\n",
       "  AIMessage(content=\"I'm doing well. And you?\", response_metadata={'finish_reason': 'stop'}, id='run-99668afc-8f36-49b2-8a45-a027e04729aa-0')]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_agent.send_text(\"lo estoy haciendo bien. ¿Y tú?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71096853-db56-4894-b35d-17f5bb156075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in supervisor\n",
      "{'messages': [HumanMessage(content=\"tu viens au bureau aujourd'hui ?\")], 'sender': None}\n",
      "content=\"tu viens au bureau aujourd'hui ?\"\n",
      "content=\"tu viens au bureau aujourd'hui ?\"\n",
      "content=\"tu viens au bureau aujourd'hui ?\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"tu viens au bureau aujourd'hui ?\"),\n",
       "  AIMessage(content='Are you coming to the office today?', response_metadata={'finish_reason': 'stop'}, id='run-397fd6a5-4f28-4051-b750-53735dcf2576-0'),\n",
       "  AIMessage(content='¿Vas a venir a la oficina hoy?', response_metadata={'finish_reason': 'stop'}, id='run-15e3a62a-b7d9-4c8c-ac03-751a5907f57d-0'),\n",
       "  AIMessage(content='Are you coming to the office today?', response_metadata={'finish_reason': 'stop'}, id='run-49669e85-e1d8-4461-bc05-b0d8288a8a02-0')]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_agent.send_text(\"tu viens au bureau aujourd'hui ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7fdc4267-47ff-43e1-9b7b-faf1ebe649e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola!\n",
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "spanish_agent.display_chat_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f9f6d94a-754e-4818-b068-f86a9abc1343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aya, what's the capital of India?\n",
      "I'm sorry, but you didn't provide any text to translate.\n",
      "I'm sorry, but you didn't provide any text to translate.\n",
      "Hey, what's the capital of India?\n",
      "I'm sorry, but you didn't provide any text to translate.\n",
      "I'm sorry, but you didn't provide any text to translate.\n",
      "Aya, what's the capital of India?\n",
      "I don't know.\n",
      "I don't know.\n",
      "Aya, what's the capital of India?\n",
      "I don't know.\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "english_agent.display_chat_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8effb61b-c11e-4da5-a6c0-d6905f93b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salut là-bas!\n",
      "Comment ça va ?\n"
     ]
    }
   ],
   "source": [
    "french_agent.display_chat_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c289323-18ae-46f0-90c6-cfed07039697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f7b86-ec25-422c-92f8-5b789d3d84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\", system_prompt,\n",
    "            ),\n",
    "            \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "366bb9fc-027e-496c-b0bc-942482fc0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_SYSTEM_PROMPT = \"\"\"You are a translator that translates text to French. Translate the text provided by the user into French. Output only the \n",
    "    translated text. If the text is already in French, do not translate and return the user's text as it is!.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "073beb14-68d6-4de8-817a-2d0948c03561",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\", USER_SYSTEM_PROMPT,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name = 'user_text'),\n",
    "            \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9683c251-77e1-42a5-b2b7-7a0bea6ee459",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ccea298-26f0-43ab-8345-304529347cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"tu viens au bureau aujourd'hui ?\", response_metadata={'finish_reason': 'stop'}, id='run-7b3c0fff-0891-406c-8d68-b02d9ed25206-0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'user_text':[\"tu viens au bureau aujourd'hui ?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6bc15-fb05-40de-ae39-b408fa324822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a747ad2c-2ac0-4189-9b95-d23b7e0f3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\", \"You are a helpful AI assistant. Try to answer the users query to the best of your ability\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name = 'user_text'),\n",
    "            \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ab63c38-afa7-4172-9871-629bc8b3f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The text \"tu viens au bureau aujourd\\'hui ?\" is already in French.', response_metadata={'finish_reason': 'stop'}, id='run-9e6480d2-fb80-4c96-ae61-452dc222796c-0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", streaming=True)\n",
    "\n",
    "chain.invoke({'user_text':[\"\"\"Convert the following text into French. If the text is already in French, return it as it is. \n",
    "tu viens au bureau aujourd'hui ?\"\"\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d3bb590-aa28-4cdb-9079-67036376eb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"tu viens au bureau aujourd'hui ?\", response_metadata={'finish_reason': 'stop'}, id='run-485b7464-5a42-4a94-acfb-5d56923d7981-0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({'user_text':[\"\"\"Convert the following text into French. \n",
    "If the text is already in French, return the original text. Return only the output text and nothing else. \n",
    "\n",
    "Text : tu viens au bureau aujourd'hui ?\"\"\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c949c95-2de6-4ef7-9d41-f79aec1d25e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
